{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76955651",
   "metadata": {},
   "source": [
    "## **Laboratorio 6**\n",
    "- Joaqu√≠n Campos - 22155\n",
    "- Sof√≠a Garc√≠a - 22210\n",
    "- Julio Garc√≠a Salas - 22076"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f1bdb",
   "metadata": {},
   "source": [
    "## **Inciso 1 y 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba436c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1‚Äì2: Cargar archivos y estructurar tweets crudos en un DataFrame\n",
    "# - Lee 'traficogt.txt' y 'tioberny.txt' (en el directorio actual o en /mnt/data/)\n",
    "# - Intenta parsear JSON (lista, objeto, o JSONL por l√≠neas) y normaliza campos b√°sicos.\n",
    "# - Guarda una muestra CSV y (si tienes pyarrow/fastparquet) un Parquet para pasos siguientes.\n",
    "# üëâ Tras ejecutar, copia aqu√≠ el bloque \"RESUMEN DE CARGA (Paso 1‚Äì2)\" que se imprime.\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# --- Localiza archivos en el directorio actual o en /mnt/data ---\n",
    "def resolve_paths():\n",
    "    local = [Path(\"traficogt.txt\"), Path(\"tioberny.txt\")]\n",
    "    mnt = [Path(\"/mnt/data/traficogt.txt\"), Path(\"/mnt/data/tioberny.txt\")]\n",
    "    final = []\n",
    "    for p_local, p_mnt in zip(local, mnt):\n",
    "        if p_local.exists():\n",
    "            final.append(p_local)\n",
    "        elif p_mnt.exists():\n",
    "            final.append(p_mnt)\n",
    "        else:\n",
    "            final.append(p_local)  # por si el usuario tiene otra ruta; marcamos como no existente\n",
    "    return final\n",
    "\n",
    "DATA_PATHS = resolve_paths()\n",
    "OUT_PARQUET = Path(\"tweets_raw.parquet\")\n",
    "OUT_SAMPLE_CSV = Path(\"tweets_raw_sample.csv\")\n",
    "\n",
    "# --- Utilidades de parseo robusto ---\n",
    "def read_any_json(path: Path) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Intenta leer un archivo que puede ser:\n",
    "      - JSON array\n",
    "      - JSON object con clave 'tweets' / 'data'\n",
    "      - JSONL (una entrada JSON por l√≠nea)\n",
    "    Devuelve una lista de dicts. Ignora l√≠neas inv√°lidas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        raw = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    raw_stripped = raw.strip()\n",
    "    records: List[Dict[str, Any]] = []\n",
    "    # 1) Intento directo: JSON √∫nico\n",
    "    try:\n",
    "        obj = json.loads(raw_stripped)\n",
    "        if isinstance(obj, list):\n",
    "            return [x for x in obj if isinstance(x, dict)]\n",
    "        elif isinstance(obj, dict):\n",
    "            if \"tweets\" in obj and isinstance(obj[\"tweets\"], list):\n",
    "                return [x for x in obj[\"tweets\"] if isinstance(x, dict)]\n",
    "            if \"data\" in obj and isinstance(obj[\"data\"], list):\n",
    "                return [x for x in obj[\"data\"] if isinstance(x, dict)]\n",
    "            return [obj]  # un solo tweet\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) JSONL por l√≠neas\n",
    "    for line in raw.splitlines():\n",
    "        s = line.strip().rstrip(\",\")\n",
    "        if not s:\n",
    "            continue\n",
    "        try:\n",
    "            rec = json.loads(s)\n",
    "            if isinstance(rec, dict):\n",
    "                records.append(rec)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return records\n",
    "\n",
    "def norm_username(u: Optional[str]) -> Optional[str]:\n",
    "    if not u:\n",
    "        return u\n",
    "    u = u.strip()\n",
    "    if u.startswith(\"@\"):\n",
    "        u = u[1:]\n",
    "    return u.lower()\n",
    "\n",
    "def extract_list_usernames(mentioned: Any) -> List[str]:\n",
    "    \"\"\"\n",
    "    Soporta formatos:\n",
    "      - [{\"username\": \"foo\"}, ...] (snscrape)\n",
    "      - [\"foo\",\"bar\"]\n",
    "      - [{\"screen_name\":\"foo\"}, ...]\n",
    "    \"\"\"\n",
    "    out: List[str] = []\n",
    "    if isinstance(mentioned, list):\n",
    "        for m in mentioned:\n",
    "            if isinstance(m, dict):\n",
    "                un = m.get(\"username\") or m.get(\"screen_name\") or m.get(\"name\")\n",
    "                if un:\n",
    "                    out.append(norm_username(un))\n",
    "            elif isinstance(m, str):\n",
    "                out.append(norm_username(m))\n",
    "    return [x for x in out if x]\n",
    "\n",
    "def hashtags_to_list(h: Any) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    if isinstance(h, list):\n",
    "        for item in h:\n",
    "            if isinstance(item, str):\n",
    "                out.append(item.lstrip(\"#\").lower())\n",
    "            elif isinstance(item, dict):\n",
    "                txt = item.get(\"text\") or item.get(\"tag\")\n",
    "                if txt:\n",
    "                    out.append(str(txt).lstrip(\"#\").lower())\n",
    "    return out\n",
    "\n",
    "def get_text(rec: Dict[str, Any]) -> Optional[str]:\n",
    "    for k in (\"rawContent\", \"full_text\", \"text\"):\n",
    "        val = rec.get(k)\n",
    "        if isinstance(val, str) and val.strip():\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "def get_user_obj(rec: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "    u = rec.get(\"user\")\n",
    "    if isinstance(u, dict):\n",
    "        return u\n",
    "    return None\n",
    "\n",
    "def safe_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def to_flat_rows(records: List[Dict[str, Any]], source_file: str) -> List[Dict[str, Any]]:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for r in records:\n",
    "        u = get_user_obj(r)\n",
    "        uname = None\n",
    "        uid = None\n",
    "        if u:\n",
    "            uname = u.get(\"username\") or u.get(\"screen_name\") or u.get(\"name\")\n",
    "            uid = u.get(\"id\") or u.get(\"id_str\")\n",
    "\n",
    "        # Mentions (snscrape: 'mentionedUsers'; API v1: entities.user_mentions)\n",
    "        mentions = []\n",
    "        if \"mentionedUsers\" in r:\n",
    "            mentions = extract_list_usernames(r.get(\"mentionedUsers\"))\n",
    "        elif \"entities\" in r and isinstance(r[\"entities\"], dict):\n",
    "            um = r[\"entities\"].get(\"user_mentions\")\n",
    "            mentions = extract_list_usernames(um)\n",
    "\n",
    "        # Hashtags\n",
    "        if \"hashtags\" in r:\n",
    "            tags = hashtags_to_list(r.get(\"hashtags\"))\n",
    "        elif \"entities\" in r and isinstance(r[\"entities\"], dict):\n",
    "            tags = hashtags_to_list(r[\"entities\"].get(\"hashtags\"))\n",
    "        else:\n",
    "            tags = []\n",
    "\n",
    "        # RT / Quote\n",
    "        rt = r.get(\"retweetedTweet\")\n",
    "        qt = r.get(\"quotedTweet\")\n",
    "        is_rt = rt is not None\n",
    "        is_qt = qt is not None\n",
    "        rt_user = norm_username(rt.get(\"user\", {}).get(\"username\")) if isinstance(rt, dict) else None\n",
    "        qt_user = norm_username(qt.get(\"user\", {}).get(\"username\")) if isinstance(qt, dict) else None\n",
    "\n",
    "        # Reply\n",
    "        in_reply_to_user = r.get(\"inReplyToUser\")\n",
    "        reply_to_username = None\n",
    "        if isinstance(in_reply_to_user, dict):\n",
    "            reply_to_username = norm_username(in_reply_to_user.get(\"username\"))\n",
    "        if not reply_to_username and r.get(\"in_reply_to_screen_name\"):\n",
    "            reply_to_username = norm_username(r.get(\"in_reply_to_screen_name\"))\n",
    "\n",
    "        # M√©tricas\n",
    "        like_count = safe_int(r.get(\"likeCount\") or r.get(\"favorite_count\"))\n",
    "        rt_count = safe_int(r.get(\"retweetCount\") or r.get(\"retweet_count\"))\n",
    "        reply_count = safe_int(r.get(\"replyCount\") or r.get(\"reply_count\"))\n",
    "        quote_count = safe_int(r.get(\"quoteCount\") or r.get(\"quote_count\"))\n",
    "        view_count = safe_int(r.get(\"viewCount\") or r.get(\"views\"))\n",
    "\n",
    "        # Fecha\n",
    "        date_raw = r.get(\"date\") or r.get(\"created_at\")\n",
    "        try:\n",
    "            date_parsed = pd.to_datetime(date_raw)\n",
    "        except Exception:\n",
    "            date_parsed = pd.NaT\n",
    "\n",
    "        rows.append({\n",
    "            \"source_file\": source_file,\n",
    "            \"tweet_id\": r.get(\"id\") or r.get(\"id_str\"),\n",
    "            \"date\": date_parsed,\n",
    "            \"lang\": r.get(\"lang\"),\n",
    "            \"username\": norm_username(uname),\n",
    "            \"user_id\": uid,\n",
    "            \"text\": get_text(r),\n",
    "            \"mentions\": mentions,\n",
    "            \"hashtags\": tags,\n",
    "            \"is_retweet\": bool(is_rt),\n",
    "            \"is_quote\": bool(is_qt),\n",
    "            \"retweeted_user\": rt_user,\n",
    "            \"quoted_user\": qt_user,\n",
    "            \"reply_to_user\": reply_to_username,\n",
    "            \"in_reply_to_tweet_id\": r.get(\"inReplyToTweetId\") or r.get(\"in_reply_to_status_id_str\") or r.get(\"in_reply_to_status_id\"),\n",
    "            \"like_count\": like_count,\n",
    "            \"retweet_count\": rt_count,\n",
    "            \"reply_count\": reply_count,\n",
    "            \"quote_count\": quote_count,\n",
    "            \"view_count\": view_count,\n",
    "            \"raw_record\": r,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "# --- Proceso de carga ---\n",
    "all_rows: List[Dict[str, Any]] = []\n",
    "summary = []\n",
    "\n",
    "for p in DATA_PATHS:\n",
    "    status = \"NO_FILE\"\n",
    "    n_lines = 0\n",
    "    n_json = 0\n",
    "    if p.exists():\n",
    "        status = \"OK\"\n",
    "        try:\n",
    "            n_lines = len(p.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines())\n",
    "        except Exception:\n",
    "            n_lines = 0\n",
    "        recs = read_any_json(p)\n",
    "        n_json = len(recs)\n",
    "        rows = to_flat_rows(recs, p.name)\n",
    "        all_rows.extend(rows)\n",
    "    summary.append((p.name, status, n_lines, n_json))\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "if not df.empty:\n",
    "    df = df.sort_values(\"date\", na_position=\"last\").reset_index(drop=True)\n",
    "\n",
    "# --- Guardados para siguientes incisos ---\n",
    "if not df.empty:\n",
    "    try:\n",
    "        df.to_parquet(OUT_PARQUET, index=False)\n",
    "        parquet_path = str(OUT_PARQUET.resolve())\n",
    "    except Exception:\n",
    "        parquet_path = \"(No se guard√≥ Parquet: falta pyarrow/fastparquet)\"\n",
    "    df.head(50).to_csv(OUT_SAMPLE_CSV, index=False)\n",
    "else:\n",
    "    parquet_path = \"(DataFrame vac√≠o)\"\n",
    "    \n",
    "# --- Salida de resumen ---\n",
    "print(\"=== RESUMEN DE CARGA (Paso 1‚Äì2) ===\")\n",
    "print(f\"Archivos buscados (existentes marcados como OK m√°s abajo):\")\n",
    "for p in DATA_PATHS:\n",
    "    print(\" -\", p)\n",
    "\n",
    "for name, status, n_lines, n_json in summary:\n",
    "    print(f\"- {name:15s} | estado={status:7s} | l√≠neas={n_lines:5d} | objetos_JSON={n_json:5d}\")\n",
    "\n",
    "print(f\"\\nTotal de filas normalizadas: {len(df):,}\")\n",
    "if not df.empty:\n",
    "    by_file = df.groupby(\"source_file\")[\"tweet_id\"].count().to_dict()\n",
    "    print(\"Filas por archivo:\", by_file)\n",
    "    print(\"Columnas estandarizadas:\", list(df.columns))\n",
    "    print(f\"Parquet: {parquet_path}\")\n",
    "    print(f\"Muestra CSV (50 filas): {str(OUT_SAMPLE_CSV.resolve())}\")\n",
    "else:\n",
    "    print(\"Nota: No se generaron archivos de salida porque no se detectaron objetos JSON v√°lidos.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
